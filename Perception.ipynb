{"cells":[{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (3.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.64.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.2.0)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.23.4)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting tensorflow\n","  Downloading tensorflow-2.10.0-cp310-cp310-macosx_10_14_x86_64.whl (241.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting libclang>=13.0.0\n","  Downloading libclang-14.0.6-py2.py3-none-macosx_10_9_x86_64.whl (13.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /Users/anthony.garcia/Library/Python/3.10/lib/python/site-packages (from tensorflow) (21.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow) (65.4.1)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n","  Downloading grpcio-1.50.0-cp310-cp310-macosx_12_0_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting keras-preprocessing>=1.1.1\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h5py>=2.9.0\n","  Downloading h5py-3.7.0-cp310-cp310-macosx_10_9_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n","  Downloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp310-cp310-macosx_10_14_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting termcolor>=1.1.0\n","  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n","Collecting opt-einsum>=2.3.2\n","  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-pasta>=0.1.1\n","  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wrapt>=1.11.0\n","  Downloading wrapt-1.14.1-cp310-cp310-macosx_10_9_x86_64.whl (35 kB)\n","Collecting absl-py>=1.0.0\n","  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=3.6.6\n","  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: six>=1.12.0 in /Users/anthony.garcia/Library/Python/3.10/lib/python/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/site-packages (from tensorflow) (1.23.4)\n","Collecting gast<=0.4.0,>=0.2.1\n","  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Collecting requests<3,>=2.21.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n","  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n","Collecting tensorboard-plugin-wit>=1.6.0\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/anthony.garcia/Library/Python/3.10/lib/python/site-packages (from packaging->tensorflow) (3.0.9)\n","Collecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting certifi>=2017.4.17\n","  Downloading certifi-2022.9.24-py3-none-any.whl (161 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting charset-normalizer<3,>=2\n","  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting idna<4,>=2.5\n","  Downloading idna-3.4-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n","Collecting pyasn1<0.5.0,>=0.4.6\n","  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting oauthlib>=3.0.0\n","  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, markdown, keras-preprocessing, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, astunparse, absl-py, requests, google-auth, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n","Successfully installed absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 flatbuffers-22.10.26 gast-0.4.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 h5py-3.7.0 idna-3.4 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.1.0 typing-extensions-4.4.0 urllib3-1.26.12 wrapt-1.14.1\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install nltk\n","%pip install numpy\n","%pip install tensorflow"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4894,"status":"ok","timestamp":1668024584193,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"w-Skvc4MK2Zt","outputId":"82124e5c-6038-4fd6-93d3-871281c05be3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     /Users/anthony.garcia/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /Users/anthony.garcia/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     /Users/anthony.garcia/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import string\n","import random\n","import nltk\n","import numpy as num\n","from nltk.stem import WordNetLemmatizer # It has the ability to lemmatize.\n","import tensorflow as tensorF # A multidimensional array of elements is represented by this symbol.\n","from tensorflow.keras import Sequential # Sequential groups a linear stack of layers into a tf.keras.Model\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","nltk.download(\"punkt\")# required package for tokenization\n","nltk.download(\"wordnet\")# word database\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1668024588803,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"_lq7Tao_K8pf"},"outputs":[],"source":["data = {\"intents\": [\n","\n","             {\"tag\": \"age\",\n","              \"patterns\": [\"how old are you?\"],\n","              \"responses\": [\"I am 2 years old and my birthday was yesterday\"]\n","             },\n","              {\"tag\": \"greeting\",\n","              \"patterns\": [ \"Hi\", \"Hello\", \"Hey\", \"What’s up?\", \"Good morning\", \"Good afternoon\", \"Good evening\"],\n","              \"responses\": [\"Hi there\", \"Hello\", \"Hi :)\"],\n","             },\n","              {\"tag\": \"goodbye\",\n","              \"patterns\": [ \"Bye\", \"later\", \"have a nice day\", \"see you\", \"talk to you later\"],\n","              \"responses\": [\"Bye\", \"Take care\", \"have a nice day\"]\n","             },\n","             {\"tag\": \"thanks\",\n","              \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\"],\n","             \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\", \"You're welcome\", \"No problem\"]\n","             },\n","             {\"tag\": \"name\",\n","              \"patterns\": [\"what's your name?\", \"who are you?\"],\n","              \"responses\": [\"I have no name yet\", \"You can give me one name and I will appreciate it\", \"Well, I'm the avatar of metaverse\"]\n","             },\n","             {\"tag\": \"question\",\n","              \"patterns\": [\"How are you?\", \"How’s it going?\", \"Are you well?\"],\n","              \"responses\": [\"Fine thanks, and you?\", \"I'm all right\", \"Good, thanks\"]\n","             }\n","]}"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2968,"status":"ok","timestamp":1668024594342,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"YiSw2HlZLAAF"},"outputs":[],"source":["lm = WordNetLemmatizer() #for getting words\n","# lists\n","ourClasses = []\n","newWords = []\n","documentX = []\n","documentY = []\n","# Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n","for intent in data[\"intents\"]:\n","    for pattern in intent[\"patterns\"]:\n","        ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n","        newWords.extend(ournewTkns)# extends the tokens\n","        documentX.append(pattern)\n","        documentY.append(intent[\"tag\"])\n","\n","\n","    if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n","        ourClasses.append(intent[\"tag\"])\n","\n","newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n","newWords = sorted(set(newWords))# sorting words\n","ourClasses = sorted(set(ourClasses))# sorting classes"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":134,"status":"ok","timestamp":1668024598423,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"ZcxJbcCsLIrp"},"outputs":[],"source":["trainingData = [] # training list array\n","outEmpty = [0] * len(ourClasses)\n","# bow model\n","for idx, doc in enumerate(documentX):\n","    bagOfwords = []\n","    text = lm.lemmatize(doc.lower())\n","    for word in newWords:\n","        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n","\n","    outputRow = list(outEmpty)\n","    outputRow[ourClasses.index(documentY[idx])] = 1\n","    trainingData.append([bagOfwords, outputRow])\n","\n","random.shuffle(trainingData)\n","trainingData = num.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n","\n","x = num.array(list(trainingData[:, 0]))# first trainig phase\n","y = num.array(list(trainingData[:, 1]))# second training phase"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3554,"status":"ok","timestamp":1668024604173,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"tbc2PqqzLLkg","outputId":"fd0a7b1d-2c45-4df2-c784-8daf101a86ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 128)               4608      \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 6)                 390       \n","                                                                 \n","=================================================================\n","Total params: 13,254\n","Trainable params: 13,254\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/200\n"]},{"name":"stderr","output_type":"stream","text":["2022-11-09 19:25:10.899343: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 785ms/step - loss: 1.8720 - accuracy: 0.0476\n","Epoch 2/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.7135 - accuracy: 0.3333\n","Epoch 3/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.6396 - accuracy: 0.2381\n","Epoch 4/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.4224 - accuracy: 0.7619\n","Epoch 5/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.3705 - accuracy: 0.6667\n","Epoch 6/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.2731 - accuracy: 0.7143\n","Epoch 7/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.1562 - accuracy: 0.6667\n","Epoch 8/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.9734 - accuracy: 0.7143\n","Epoch 9/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.9452 - accuracy: 0.7143\n","Epoch 10/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.8379 - accuracy: 0.7143\n","Epoch 11/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.8571\n","Epoch 12/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.7143\n","Epoch 13/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.8095\n","Epoch 14/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.4014 - accuracy: 0.8571\n","Epoch 15/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.9048\n","Epoch 16/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9048\n","Epoch 17/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8571\n","Epoch 18/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9048\n","Epoch 19/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.1879 - accuracy: 0.9524\n","Epoch 20/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9524\n","Epoch 21/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9524\n","Epoch 22/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 1.0000\n","Epoch 23/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 1.0000\n","Epoch 24/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9524\n","Epoch 25/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 1.0000\n","Epoch 26/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000\n","Epoch 27/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 1.0000\n","Epoch 28/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0630 - accuracy: 1.0000\n","Epoch 29/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000\n","Epoch 30/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 1.0000\n","Epoch 31/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0622 - accuracy: 1.0000\n","Epoch 32/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 1.0000\n","Epoch 33/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 34/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 1.0000\n","Epoch 35/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n","Epoch 36/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 1.0000\n","Epoch 37/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 1.0000\n","Epoch 38/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 1.0000\n","Epoch 39/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000\n","Epoch 40/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000\n","Epoch 41/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n","Epoch 42/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 1.0000\n","Epoch 43/200\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0240 - accuracy: 1.0000\n","Epoch 44/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9524\n","Epoch 45/200\n","1/1 [==============================] - 0s 4ms/step - loss: 7.2207e-04 - accuracy: 1.0000\n","Epoch 46/200\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 47/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 48/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0253 - accuracy: 1.0000\n","Epoch 49/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0643 - accuracy: 0.9524\n","Epoch 50/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 51/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 52/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 53/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 1.0000\n","Epoch 54/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 55/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 56/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 57/200\n","1/1 [==============================] - 0s 4ms/step - loss: 5.7379e-04 - accuracy: 1.0000\n","Epoch 58/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 1.0000\n","Epoch 59/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 60/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 1.0000\n","Epoch 61/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0425 - accuracy: 0.9524\n","Epoch 62/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 63/200\n","1/1 [==============================] - 0s 3ms/step - loss: 9.2327e-04 - accuracy: 1.0000\n","Epoch 64/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 65/200\n","1/1 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n","Epoch 66/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 67/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.4071e-04 - accuracy: 1.0000\n","Epoch 68/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9524\n","Epoch 69/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 70/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9524\n","Epoch 71/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000\n","Epoch 72/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000\n","Epoch 73/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.4349e-04 - accuracy: 1.0000\n","Epoch 74/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9524\n","Epoch 75/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n","Epoch 76/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 77/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n","Epoch 78/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 79/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 1.0000\n","Epoch 80/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 81/200\n","1/1 [==============================] - 0s 2ms/step - loss: 5.5179e-04 - accuracy: 1.0000\n","Epoch 82/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 83/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 84/200\n","1/1 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 85/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 86/200\n","1/1 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000\n","Epoch 87/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 88/200\n","1/1 [==============================] - 0s 3ms/step - loss: 8.0069e-04 - accuracy: 1.0000\n","Epoch 89/200\n","1/1 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n","Epoch 90/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n","Epoch 91/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.5688e-04 - accuracy: 1.0000\n","Epoch 92/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.1770e-04 - accuracy: 1.0000\n","Epoch 93/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000\n","Epoch 94/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 1.0000\n","Epoch 95/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 96/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 97/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 98/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.1431e-04 - accuracy: 1.0000\n","Epoch 99/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.0763e-04 - accuracy: 1.0000\n","Epoch 100/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.8725e-04 - accuracy: 1.0000\n","Epoch 101/200\n","1/1 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000\n","Epoch 102/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 103/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000\n","Epoch 104/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 105/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.5714e-04 - accuracy: 1.0000\n","Epoch 106/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 107/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 1.0000\n","Epoch 108/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000\n","Epoch 109/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 110/200\n","1/1 [==============================] - 0s 2ms/step - loss: 9.0173e-05 - accuracy: 1.0000\n","Epoch 111/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000\n","Epoch 112/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.0761e-04 - accuracy: 1.0000\n","Epoch 113/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 114/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.9471e-04 - accuracy: 1.0000\n","Epoch 115/200\n","1/1 [==============================] - 0s 3ms/step - loss: 2.5068e-04 - accuracy: 1.0000\n","Epoch 116/200\n","1/1 [==============================] - 0s 4ms/step - loss: 9.5196e-05 - accuracy: 1.0000\n","Epoch 117/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 118/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 119/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 120/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.5858e-04 - accuracy: 1.0000\n","Epoch 121/200\n","1/1 [==============================] - 0s 2ms/step - loss: 1.8460e-04 - accuracy: 1.0000\n","Epoch 122/200\n","1/1 [==============================] - 0s 4ms/step - loss: 7.7644e-04 - accuracy: 1.0000\n","Epoch 123/200\n","1/1 [==============================] - 0s 3ms/step - loss: 2.7111e-04 - accuracy: 1.0000\n","Epoch 124/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.5359e-04 - accuracy: 1.0000\n","Epoch 125/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.9116e-04 - accuracy: 1.0000\n","Epoch 126/200\n","1/1 [==============================] - 0s 33ms/step - loss: 5.1631e-04 - accuracy: 1.0000\n","Epoch 127/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 128/200\n","1/1 [==============================] - 0s 6ms/step - loss: 8.0599e-04 - accuracy: 1.0000\n","Epoch 129/200\n","1/1 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 130/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n","Epoch 131/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 132/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 133/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 134/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 135/200\n","1/1 [==============================] - 0s 3ms/step - loss: 8.3802e-04 - accuracy: 1.0000\n","Epoch 136/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 1.0000\n","Epoch 137/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000\n","Epoch 138/200\n","1/1 [==============================] - 0s 3ms/step - loss: 2.0307e-04 - accuracy: 1.0000\n","Epoch 139/200\n","1/1 [==============================] - 0s 3ms/step - loss: 4.1318e-04 - accuracy: 1.0000\n","Epoch 140/200\n","1/1 [==============================] - 0s 4ms/step - loss: 3.1274e-04 - accuracy: 1.0000\n","Epoch 141/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.9135e-05 - accuracy: 1.0000\n","Epoch 142/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.6761e-04 - accuracy: 1.0000\n","Epoch 143/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.8014e-05 - accuracy: 1.0000\n","Epoch 144/200\n","1/1 [==============================] - 0s 4ms/step - loss: 2.5041e-04 - accuracy: 1.0000\n","Epoch 145/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.1960e-04 - accuracy: 1.0000\n","Epoch 146/200\n","1/1 [==============================] - 0s 4ms/step - loss: 6.9804e-04 - accuracy: 1.0000\n","Epoch 147/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 148/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.8655e-04 - accuracy: 1.0000\n","Epoch 149/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 150/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.1055e-04 - accuracy: 1.0000\n","Epoch 151/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.3557e-04 - accuracy: 1.0000\n","Epoch 152/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.7423e-04 - accuracy: 1.0000\n","Epoch 153/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.3199e-04 - accuracy: 1.0000\n","Epoch 154/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.1188e-04 - accuracy: 1.0000\n","Epoch 155/200\n","1/1 [==============================] - 0s 3ms/step - loss: 4.8669e-04 - accuracy: 1.0000\n","Epoch 156/200\n","1/1 [==============================] - 0s 4ms/step - loss: 9.2312e-05 - accuracy: 1.0000\n","Epoch 157/200\n","1/1 [==============================] - 0s 3ms/step - loss: 8.3450e-05 - accuracy: 1.0000\n","Epoch 158/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000\n","Epoch 159/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.2757e-05 - accuracy: 1.0000\n","Epoch 160/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.7548e-04 - accuracy: 1.0000\n","Epoch 161/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.4411e-04 - accuracy: 1.0000\n","Epoch 162/200\n","1/1 [==============================] - 0s 3ms/step - loss: 6.8807e-04 - accuracy: 1.0000\n","Epoch 163/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.0060e-04 - accuracy: 1.0000\n","Epoch 164/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 165/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.5433e-04 - accuracy: 1.0000\n","Epoch 166/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 167/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 1.0000\n","Epoch 168/200\n","1/1 [==============================] - 0s 3ms/step - loss: 9.2880e-04 - accuracy: 1.0000\n","Epoch 169/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n","Epoch 170/200\n","1/1 [==============================] - 0s 4ms/step - loss: 1.2467e-04 - accuracy: 1.0000\n","Epoch 171/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.1353e-05 - accuracy: 1.0000\n","Epoch 172/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.7571e-04 - accuracy: 1.0000\n","Epoch 173/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.0250e-04 - accuracy: 1.0000\n","Epoch 174/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 175/200\n","1/1 [==============================] - 0s 4ms/step - loss: 7.0714e-04 - accuracy: 1.0000\n","Epoch 176/200\n","1/1 [==============================] - 0s 7ms/step - loss: 1.5704e-04 - accuracy: 1.0000\n","Epoch 177/200\n","1/1 [==============================] - 0s 15ms/step - loss: 4.9214e-04 - accuracy: 1.0000\n","Epoch 178/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 179/200\n","1/1 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 180/200\n","1/1 [==============================] - 0s 7ms/step - loss: 2.6120e-04 - accuracy: 1.0000\n","Epoch 181/200\n","1/1 [==============================] - 0s 4ms/step - loss: 2.1731e-04 - accuracy: 1.0000\n","Epoch 182/200\n","1/1 [==============================] - 0s 4ms/step - loss: 7.4974e-05 - accuracy: 1.0000\n","Epoch 183/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n","Epoch 184/200\n","1/1 [==============================] - 0s 3ms/step - loss: 8.1509e-04 - accuracy: 1.0000\n","Epoch 185/200\n","1/1 [==============================] - 0s 3ms/step - loss: 7.7405e-04 - accuracy: 1.0000\n","Epoch 186/200\n","1/1 [==============================] - 0s 4ms/step - loss: 4.8016e-04 - accuracy: 1.0000\n","Epoch 187/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 188/200\n","1/1 [==============================] - 0s 3ms/step - loss: 3.6254e-04 - accuracy: 1.0000\n","Epoch 189/200\n","1/1 [==============================] - 0s 4ms/step - loss: 2.7650e-05 - accuracy: 1.0000\n","Epoch 190/200\n","1/1 [==============================] - 0s 3ms/step - loss: 5.4125e-05 - accuracy: 1.0000\n","Epoch 191/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000\n","Epoch 192/200\n","1/1 [==============================] - 0s 4ms/step - loss: 2.3396e-04 - accuracy: 1.0000\n","Epoch 193/200\n","1/1 [==============================] - 0s 3ms/step - loss: 9.0150e-04 - accuracy: 1.0000\n","Epoch 194/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 195/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.3866e-04 - accuracy: 1.0000\n","Epoch 196/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.6501e-05 - accuracy: 1.0000\n","Epoch 197/200\n","1/1 [==============================] - 0s 3ms/step - loss: 1.7783e-04 - accuracy: 1.0000\n","Epoch 198/200\n","1/1 [==============================] - 0s 2ms/step - loss: 6.3060e-05 - accuracy: 1.0000\n","Epoch 199/200\n","1/1 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9524\n","Epoch 200/200\n","1/1 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x133ba6b30>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["iShape = (len(x[0]),)\n","oShape = len(y[0])\n","# parameter definition\n","ourNewModel = Sequential()\n","# In the case of a simple stack of layers, a Sequential model is appropriate\n","\n","# Dense function adds an output layer\n","ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n","# The activation function in a neural network is in charge of converting the node's summed weighted input into activation of the node or output for the input in question\n","ourNewModel.add(Dropout(0.5))\n","# Dropout is used to enhance visual perception of input neurons\n","ourNewModel.add(Dense(64, activation=\"relu\"))\n","ourNewModel.add(Dropout(0.3))\n","ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n","# below is a callable that returns the value to be used with no arguments\n","md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n","# Below line improves the numerical stability and pushes the computation of the probability distribution into the categorical crossentropy loss function.\n","ourNewModel.compile(loss='categorical_crossentropy',\n","              optimizer=md,\n","              metrics=[\"accuracy\"])\n","# Output the model in summary\n","print(ourNewModel.summary())\n","# Whilst training your Nural Network, you have the option of making the output verbose or simple.\n","ourNewModel.fit(x, y, epochs=200, verbose=1)\n","# By epochs, we mean the number of times you repeat a training set."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":168,"status":"ok","timestamp":1668024609023,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"bYReDY0fLQB0"},"outputs":[],"source":["def ourText(text):\n","  newtkns = nltk.word_tokenize(text)\n","  newtkns = [lm.lemmatize(word) for word in newtkns]\n","  return newtkns\n","\n","def wordBag(text, vocab):\n","  newtkns = ourText(text)\n","  bagOwords = [0] * len(vocab)\n","  for w in newtkns:\n","    for idx, word in enumerate(vocab):\n","      if word == w:\n","        bagOwords[idx] = 1\n","  return num.array(bagOwords)\n","\n","def Pclass(text, vocab, labels):\n","  bagOwords = wordBag(text, vocab)\n","  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n","  newThresh = 0.2\n","  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n","\n","  yp.sort(key=lambda x: x[1], reverse=True)\n","  newList = []\n","  for r in yp:\n","    newList.append(labels[r[0]])\n","  return newList\n","\n","def getRes(firstlist, fJson):\n","  tag = firstlist[0]\n","  listOfIntents = fJson[\"intents\"]\n","  for i in listOfIntents:\n","    if i[\"tag\"] == tag:\n","      ourResult = random.choice(i[\"responses\"])\n","      break\n","  return ourResult"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":55009,"status":"error","timestamp":1668024806553,"user":{"displayName":"Katherin Valencia Correa","userId":"14444679095885904042"},"user_tz":300},"id":"R6Qj0yS2LYUZ","outputId":"fd7b4bb6-79d8-48b5-d409-2e30e0cdb552"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: Flask in /usr/local/lib/python3.10/site-packages (2.2.2)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/site-packages (from Flask) (2.1.2)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/site-packages (from Flask) (3.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/site-packages (from Flask) (8.1.3)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/site-packages (from Flask) (2.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from Jinja2>=3.0->Flask) (2.1.1)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install Flask"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
